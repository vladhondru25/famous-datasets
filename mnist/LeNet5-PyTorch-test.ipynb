{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aim\n",
    "The aim of this notebook is to test whether the placement of the activation function (before or after the sub-sampling operation) has any effect. Although minimal for this example, it had an impact, resulting in a higher accuracy to place the activation function after the max-pooling operations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, sampler\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameters\n",
    "LEARNING_RATE = 1e-3\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: False\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if use_cuda else 'cpu')\n",
    "print(\"Using GPU: {}\".format(use_cuda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed during training for reproducibility\n",
    "torch.manual_seed(0)\n",
    "if use_cuda:\n",
    "    torch.cuda.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get MNIST data\n",
    "train_dat = datasets.MNIST(\"data/\", train=True, transform=transforms.ToTensor(), download=True)#, transform=transform)\n",
    "test_dat = datasets.MNIST(\"data/\", transform=transforms.ToTensor(), train=False)#, transform=transform)\n",
    "# train_dat[index][0] -> Image\n",
    "# train_dat[index][1] -> Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataloaders for iterating over the datasets\n",
    "train_loader = DataLoader(train_dat, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dat, batch_size=BATCH_SIZE, shuffle=False)\n",
    "# Add validation set and sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Maximum pooling is used, unlike the original architecture where average pooling is used\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lenet = nn.Sequential(\n",
    "                        nn.Conv2d(in_channels=1, out_channels=6,  kernel_size=5, stride=1, padding=2),\n",
    "                        nn.ReLU(inplace=True),\n",
    "                        nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "                        nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0),\n",
    "                        nn.ReLU(inplace=True),\n",
    "                        nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "                        nn.Flatten(),\n",
    "                        nn.Linear(in_features=400, out_features=120),\n",
    "                        nn.ReLU(inplace=True),\n",
    "                        nn.Linear(in_features=120, out_features=84),\n",
    "                        nn.ReLU(inplace=True),\n",
    "                        nn.Linear(in_features=84,  out_features=10)\n",
    "                     )\n",
    "    def forward(self,x):\n",
    "        return self.lenet(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Maximum pooling is used, unlike the original architecture where average pooling is used\n",
    "class LeNet5v2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lenet = nn.Sequential(\n",
    "                        nn.Conv2d(in_channels=1, out_channels=6,  kernel_size=5, stride=1, padding=2),\n",
    "                        nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "                        nn.ReLU(inplace=True),\n",
    "                        nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0),\n",
    "                        nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "                        nn.ReLU(inplace=True),\n",
    "                        nn.Flatten(),\n",
    "                        nn.Linear(in_features=400, out_features=120),\n",
    "                        nn.ReLU(inplace=True),\n",
    "                        nn.Linear(in_features=120, out_features=84),\n",
    "                        nn.ReLU(inplace=True),\n",
    "                        nn.Linear(in_features=84,  out_features=10)\n",
    "                     )\n",
    "    def forward(self,x):\n",
    "        return self.lenet(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(pred, y):\n",
    "    return F.cross_entropy(pred, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 2.30\n",
      "Iteration 0, loss2 = 2.30\n",
      "Iteration 100, loss = 0.34\n",
      "Iteration 100, loss2 = 0.38\n",
      "Iteration 200, loss = 0.38\n",
      "Iteration 200, loss2 = 0.26\n",
      "Iteration 300, loss = 0.15\n",
      "Iteration 300, loss2 = 0.18\n",
      "Iteration 400, loss = 0.10\n",
      "Iteration 400, loss2 = 0.09\n",
      "Iteration 500, loss = 0.10\n",
      "Iteration 500, loss2 = 0.08\n",
      "Iteration 600, loss = 0.07\n",
      "Iteration 600, loss2 = 0.09\n",
      "Iteration 700, loss = 0.03\n",
      "Iteration 700, loss2 = 0.06\n",
      "Iteration 800, loss = 0.07\n",
      "Iteration 800, loss2 = 0.06\n",
      "Iteration 900, loss = 0.08\n",
      "Iteration 900, loss2 = 0.08\n",
      "Iteration 1000, loss = 0.01\n",
      "Iteration 1000, loss2 = 0.02\n",
      "Iteration 1100, loss = 0.09\n",
      "Iteration 1100, loss2 = 0.12\n",
      "Iteration 1200, loss = 0.06\n",
      "Iteration 1200, loss2 = 0.04\n",
      "Iteration 1300, loss = 0.08\n",
      "Iteration 1300, loss2 = 0.10\n",
      "Iteration 1400, loss = 0.02\n",
      "Iteration 1400, loss2 = 0.03\n",
      "Iteration 1500, loss = 0.02\n",
      "Iteration 1500, loss2 = 0.02\n",
      "Iteration 1600, loss = 0.02\n",
      "Iteration 1600, loss2 = 0.03\n",
      "Iteration 1700, loss = 0.04\n",
      "Iteration 1700, loss2 = 0.04\n",
      "Iteration 1800, loss = 0.04\n",
      "Iteration 1800, loss2 = 0.05\n",
      "Iteration 1900, loss = 0.02\n",
      "Iteration 1900, loss2 = 0.02\n",
      "Iteration 2000, loss = 0.09\n",
      "Iteration 2000, loss2 = 0.05\n",
      "Iteration 2100, loss = 0.03\n",
      "Iteration 2100, loss2 = 0.04\n",
      "Iteration 2200, loss = 0.06\n",
      "Iteration 2200, loss2 = 0.05\n",
      "Iteration 2300, loss = 0.06\n",
      "Iteration 2300, loss2 = 0.07\n",
      "Iteration 2400, loss = 0.03\n",
      "Iteration 2400, loss2 = 0.04\n",
      "Iteration 2500, loss = 0.04\n",
      "Iteration 2500, loss2 = 0.02\n",
      "Iteration 2600, loss = 0.03\n",
      "Iteration 2600, loss2 = 0.05\n",
      "Iteration 2700, loss = 0.03\n",
      "Iteration 2700, loss2 = 0.04\n",
      "Iteration 2800, loss = 0.01\n",
      "Iteration 2800, loss2 = 0.01\n",
      "Iteration 2900, loss = 0.01\n",
      "Iteration 2900, loss2 = 0.02\n"
     ]
    }
   ],
   "source": [
    "lenet = LeNet5()\n",
    "lenet = lenet.to(device=device)\n",
    "\n",
    "lenet2 = LeNet5v2()\n",
    "lenet2 = lenet2.to(device=device)\n",
    "\n",
    "optimizer = optim.Adam(lenet.parameters(), lr=LEARNING_RATE)\n",
    "optimizer2 = optim.Adam(lenet2.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "training_loss = []\n",
    "training_loss2 = []\n",
    "\n",
    "# Start training\n",
    "lenet.train()\n",
    "lenet2.train()\n",
    "for epoch in range(EPOCHS):\n",
    "    for i, (x,y) in enumerate(train_loader): \n",
    "        x = x.to(device=device, dtype=torch.float32)  # Use GPU\n",
    "        y = y.to(device=device, dtype=torch.long)     #  if applicable\n",
    "        \n",
    "        # Forward pass through the network\n",
    "        scores = lenet(x) \n",
    "        scores2 = lenet2(x) \n",
    "        # Compute the loss of the predictions\n",
    "        loss = loss_function(scores, y)\n",
    "        loss2 = loss_function(scores2, y)\n",
    "        \n",
    "        # Set the gradients to zero\n",
    "        optimizer.zero_grad()\n",
    "        optimizer2.zero_grad()\n",
    "        \n",
    "        # Compute the gradients of the loss with respect to the weights\n",
    "        loss.backward()\n",
    "        loss2.backward()\n",
    "        \n",
    "        # Update the weights of the model (Back-propagation)\n",
    "        optimizer.step()\n",
    "        optimizer2.step()\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print('Iteration {}, loss = {:.2f}'.format(epoch*1000 + i, loss.item()))\n",
    "            training_loss.append(loss.item())\n",
    "            print('Iteration {}, loss2 = {:.2f}'.format(epoch*1000 + i, loss2.item()))\n",
    "            training_loss2.append(loss2.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(training_loss, 'r')\n",
    "plt.plot(training_loss2, 'b')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['T1','T2'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct predictions: 9842 / 10000, with accuracy = (98.42)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "lenet.eval()\n",
    "\n",
    "num_correct = 0\n",
    "num_samples = 0\n",
    "lenet.eval()  # set model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    for x, y in test_loader:\n",
    "        x = x.to(device=device, dtype=torch.float32)  # Use GPU\n",
    "        y = y.to(device=device, dtype=torch.long)     #  if applicable\n",
    "        \n",
    "        scores = lenet(x)\n",
    "        \n",
    "        _, preds = scores.max(1)\n",
    "        \n",
    "        num_correct += (preds == y).sum()\n",
    "        num_samples += preds.size(0)\n",
    "        \n",
    "    accuracy = float(num_correct) / num_samples\n",
    "    print('Correct predictions: %d / %d, with accuracy = (%.2f)' % (num_correct, num_samples, 100 * accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct predictions: 9862 / 10000, with accuracy = (98.62)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "lenet2.eval()\n",
    "\n",
    "num_correct = 0\n",
    "num_samples = 0\n",
    "lenet2.eval()  # set model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    for x, y in test_loader:\n",
    "        x = x.to(device=device, dtype=torch.float32)  # Use GPU\n",
    "        y = y.to(device=device, dtype=torch.long)     #  if applicable\n",
    "        \n",
    "        scores = lenet2(x)\n",
    "        \n",
    "        _, preds = scores.max(1)\n",
    "        \n",
    "        num_correct += (preds == y).sum()\n",
    "        num_samples += preds.size(0)\n",
    "        \n",
    "    accuracy = float(num_correct) / num_samples\n",
    "    print('Correct predictions: %d / %d, with accuracy = (%.2f)' % (num_correct, num_samples, 100 * accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save weights if desired\n",
    "torch.save(lenet.state_dict(), 'model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
